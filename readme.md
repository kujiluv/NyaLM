# NyaLM â€” chat CLI local (LM Studio)

![Node >=18](https://img.shields.io/badge/node-%3E%3D18-43853d?logo=node.js&logoColor=white) ![CLI](https://img.shields.io/badge/interface-CLI-0d6efd) ![LM Studio](https://img.shields.io/badge/backend-LM%20Studio-ff69b4)

> Un mini compagnon en ligne de commande pour discuter avec un modÃ¨le LM Studio en local. Simple, agrÃ©able Ã  bidouiller, et prÃªt pour Ã©voluer.

## âœ¨ Ce que Ã§a fait dÃ©jÃ 
- ğŸ¤ Se connecte Ã  ton serveur LM Studio local.
- ğŸ’¬ Chat en CLI avec historique en mÃ©moire.
- ğŸ§­ Commandes rapides : `/help`, `/clear`, `/save`, `exit`.
- ğŸ’¾ Sauvegarde JSON dans `save/` (`chat-<timestamp>.json`).

## ğŸ§° PrÃ©-requis
- Node.js **18+** (testÃ© avec Node 24).
- LM Studio installÃ© avec un modÃ¨le chargÃ©.
- Serveur LM Studio dÃ©marrÃ© (ex. `http://localhost:1234/v1`).

## âš™ï¸ Configuration (`config.json`)
```json
{
  "baseUrl": "http://localhost:1234/v1",
  "model": "huihui-qwen3-30b-a3b-instruct-2507-abliterated",
  "temperature": 0.7,
  "maxTokens": 250,
  "ui": {
    "theme": "black&white",
    "language": "fr"
  }
}
```
- `baseUrl` : URL du serveur LM Studio local.  
- `model` : nom exact du modÃ¨le chargÃ©.  
- `temperature` / `maxTokens` : rÃ©glages de gÃ©nÃ©ration.  
- `ui` : prÃ©fÃ©rences dâ€™affichage (facultatif pour le chat).

## ğŸš€ Installer & lancer
```bash
git clone <ton_repo>
cd NyaLM
npm install   # pas de deps ? npm install ne fait rien, c'est ok

npm start     # ou node index.js
```
Ensuite tu arrives sur lâ€™invite `Toi >`.

## âŒ¨ï¸ Commandes utiles
- `/help` â€” affiche lâ€™aide.
- `/clear` â€” vide lâ€™historique en mÃ©moire.
- `/save` â€” Ã©crit `save/chat-<timestamp>.json`.
- `exit` â€” quitte proprement.

## ğŸ—‚ï¸ Structure du projet
```
NyaLM/
â”œâ”€ index.js              # Point dâ€™entrÃ©e
â”œâ”€ config.json           # RÃ©glages LM Studio + UI
â”œâ”€ save/                 # Sauvegardes de conversations
â””â”€ src/
   â”œâ”€ lmstudioClient.js  # Appels API LM Studio
   â”œâ”€ chatSession.js     # Historique + envoi des messages
   â”œâ”€ cli.js             # Interface console + commandes
   â””â”€ commands/
      â”œâ”€ help.js
      â”œâ”€ clear.js
      â””â”€ save.js
```

## ğŸ›£ï¸ Roadmap courte
- Streaming token par token.
- Charger une sauvegarde (`/load`).
- Changer de modÃ¨le en direct (`/model`).
- RÃ©glages live (`/temp`, `/maxtokens`).
- MÃ©moire persistante entre sessions.
- Petite interface web.
- Tool calling (appels de fonctions JS).

## ğŸ“ TODO / idÃ©es Ã  venir
- [x] GÃ©nÃ©rateur de doc : commande pour fabriquer automatiquement un README ou une fiche de features.
- [x] Export Markdown/texte des conversations (en plus du JSON).
- [x] Commande `/load` pour reprendre une sauvegarde.
- [x] ThÃ¨mes console (couleurs, prompts custom).
- [x] Mode auto-save (sauvegarde pÃ©riodique ou Ã  chaque rÃ©ponse).

## ğŸ©º DÃ©pannage rapide
- `model not found` â†’ vÃ©rifie que `model` correspond au nom exact dans LM Studio.  
- `Failed to parse URL from undefined/...` â†’ revois `baseUrl` dans `config.json`.  
- `ECONNREFUSED` / `Failed to fetch` â†’ serveur LM Studio Ã©teint ou mauvais port.  

## ğŸ¤ Contribuer
Projet en mode â€œlearning in publicâ€. Ouvre une issue, propose une PR, ou partage tes idÃ©es de commandes/fonctionnalitÃ©s. Toute aide est la bienvenue !
